{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:05:21.194663Z","iopub.execute_input":"2023-07-25T20:05:21.195046Z","iopub.status.idle":"2023-07-25T20:05:30.865781Z","shell.execute_reply.started":"2023-07-25T20:05:21.195011Z","shell.execute_reply":"2023-07-25T20:05:30.864746Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # input: N x channels_img x 64 x 64\n            nn.Conv2d(\n                channels_img, features_d, kernel_size=4, stride=2, padding=1\n            ),\n            nn.LeakyReLU(0.2),\n            # _block(in_channels, out_channels, kernel_size, stride, padding)\n            self._block(features_d, features_d * 2, 4, 2, 1),\n            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.InstanceNorm2d(out_channels, affine=True),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.disc(x)\n\n\nclass Generator(nn.Module):\n    def __init__(self, channels_noise, channels_img, features_g):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            # Input: N x channels_noise x 1 x 1\n            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n            nn.ConvTranspose2d(\n                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n            ),\n            # Output: N x channels_img x 64 x 64\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:05:30.867886Z","iopub.execute_input":"2023-07-25T20:05:30.868615Z","iopub.status.idle":"2023-07-25T20:05:30.884801Z","shell.execute_reply.started":"2023-07-25T20:05:30.868580Z","shell.execute_reply":"2023-07-25T20:05:30.883595Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def initialize_weights(model):\n    # Initializes weights according to the DCGAN paper\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n            nn.init.normal_(m.weight.data, 0.0, 0.02)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:05:30.886276Z","iopub.execute_input":"2023-07-25T20:05:30.886700Z","iopub.status.idle":"2023-07-25T20:05:30.898278Z","shell.execute_reply.started":"2023-07-25T20:05:30.886663Z","shell.execute_reply":"2023-07-25T20:05:30.897383Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters etc\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 5e-5\nBATCH_SIZE = 64\nIMAGE_SIZE = 64\nCHANNELS_IMG = 1\nZ_DIM = 128\nNUM_EPOCHS = 5\nFEATURES_CRITIC = 64\nFEATURES_GEN = 64\nCRITIC_ITERATIONS = 5\nWEIGHT_CLIP = 0.01\n","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:05:35.295494Z","iopub.execute_input":"2023-07-25T20:05:35.295878Z","iopub.status.idle":"2023-07-25T20:05:35.367563Z","shell.execute_reply.started":"2023-07-25T20:05:35.295849Z","shell.execute_reply":"2023-07-25T20:05:35.366451Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"transforms = transforms.Compose(\n    [\n        transforms.Resize(IMAGE_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n        ),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:06:12.322458Z","iopub.execute_input":"2023-07-25T20:06:12.322835Z","iopub.status.idle":"2023-07-25T20:06:12.329041Z","shell.execute_reply.started":"2023-07-25T20:06:12.322803Z","shell.execute_reply":"2023-07-25T20:06:12.327828Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n#comment mnist and uncomment below if you want to train on CelebA dataset\n#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\nloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n# initialize gen and disc/critic\ngen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\ncritic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\ninitialize_weights(gen)\ninitialize_weights(critic)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:06:12.503705Z","iopub.execute_input":"2023-07-25T20:06:12.504383Z","iopub.status.idle":"2023-07-25T20:06:19.590726Z","shell.execute_reply.started":"2023-07-25T20:06:12.504348Z","shell.execute_reply":"2023-07-25T20:06:19.589611Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 70272450.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 71593199.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 25527147.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 21120320.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# initializate optimizer\nopt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\nopt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n\n# for tensorboard plotting\nfixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\nwriter_real = SummaryWriter(f\"logs/real\")\nwriter_fake = SummaryWriter(f\"logs/fake\")\nstep = 0\n\ngen.train()\ncritic.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:06:22.493546Z","iopub.execute_input":"2023-07-25T20:06:22.494249Z","iopub.status.idle":"2023-07-25T20:06:22.510721Z","shell.execute_reply.started":"2023-07-25T20:06:22.494209Z","shell.execute_reply":"2023-07-25T20:06:22.509645Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Discriminator(\n  (disc): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2)\n    (2): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.2)\n    )\n    (3): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.2)\n    )\n    (4): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.2)\n    )\n    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    # Target labels not needed! <3 unsupervised\n    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n        data = data.to(device)\n        cur_batch_size = data.shape[0]\n\n        # Train Critic: max E[critic(real)] - E[critic(fake)]\n        for _ in range(CRITIC_ITERATIONS):\n            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n            fake = gen(noise)\n            critic_real = critic(data).reshape(-1)\n            critic_fake = critic(fake).reshape(-1)\n            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n            critic.zero_grad()\n            loss_critic.backward(retain_graph=True)\n            opt_critic.step()\n\n            # clip critic weights between -0.01, 0.01\n            for p in critic.parameters():\n                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n\n        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n        gen_fake = critic(fake).reshape(-1)\n        loss_gen = -torch.mean(gen_fake)\n        gen.zero_grad()\n        loss_gen.backward()\n        opt_gen.step()\n\n        # Print losses occasionally and print to tensorboard\n        if batch_idx % 100 == 0 and batch_idx > 0:\n            gen.eval()\n            critic.eval()\n            print(\n                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n            )\n\n            with torch.no_grad():\n                fake = gen(noise)\n                # take out (up to) 32 examples\n                img_grid_real = torchvision.utils.make_grid(\n                    data[:32], normalize=True\n                )\n                img_grid_fake = torchvision.utils.make_grid(\n                    fake[:32], normalize=True\n                )\n\n                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n\n            step += 1\n            gen.train()\n            critic.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-25T20:06:36.484342Z","iopub.execute_input":"2023-07-25T20:06:36.484738Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 11%|█         | 101/938 [01:01<08:52,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/5] Batch 100/938                   Loss D: -1.3762, loss G: 0.6806\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 201/938 [01:58<08:15,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/5] Batch 200/938                   Loss D: -1.5202, loss G: 0.7521\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 301/938 [02:57<06:59,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/5] Batch 300/938                   Loss D: -1.5328, loss G: 0.7571\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 401/938 [03:55<05:54,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/5] Batch 400/938                   Loss D: -1.5331, loss G: 0.7580\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 501/938 [04:53<04:49,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/5] Batch 500/938                   Loss D: -1.5377, loss G: 0.7589\n","output_type":"stream"},{"name":"stderr","text":" 60%|█████▉    | 561/938 [05:27<03:38,  1.73it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}